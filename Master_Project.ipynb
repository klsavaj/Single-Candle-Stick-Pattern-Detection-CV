{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4678da41-533f-4521-be55-7f677a63aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1\n",
      " GPU Detected: Tesla P100-PCIE-12GB\n",
      "   Available GPUs: 4\n",
      "==================================================\n",
      "PROJECT CONFIGURATION SUMMARY\n",
      "==================================================\n",
      "Project Root: /home/savaj.k/PRCV-Project\n",
      "Number of Classes: 6\n",
      "Classes: Dragonfly Doji, Gravestone Doji, Hammer, Hanging Man, Marubozu, Spinning Top\n",
      "Model Architecture: yolov8s.pt\n",
      "Training Epochs: 50\n",
      "Batch Size: 16\n",
      "Image Size: 640\n",
      "API Key Set: No\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "import sys\n",
    "sys.path.insert(0, '/home/savaj.k/.local/lib/python3.10/site-packages')\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project root to path\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.append(str(Path.cwd()))\n",
    "\n",
    "# Check GPU\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\" GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Available GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\" No GPU detected!\")\n",
    "\n",
    "# Import project modules\n",
    "from src.config import (\n",
    "    RAW_DATA_DIR, DATASET_YAML, WEIGHTS_DIR, \n",
    "    CLASS_NAMES, NUM_CLASSES, create_directories, print_config_summary\n",
    ")\n",
    "from src.data_utils import verify_dataset_structure, create_data_yaml, print_dataset_summary\n",
    "from src.pattern_detector import PatternDetector\n",
    "\n",
    "create_directories()\n",
    "print_config_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1752ed7a-38cc-47f0-86b6-943f933f1496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: DATA VERIFICATION\n",
      "============================================================\n",
      "Checking dataset structure...\n",
      "----------------------------------------\n",
      "  [OK] raw/train/images\n",
      "  [OK] raw/train/labels\n",
      "  [OK] raw/valid/images\n",
      "  [OK] raw/valid/labels\n",
      "  [OK] raw/data.yaml\n",
      "  [OK] raw/test/images\n",
      "  [OK] raw/test/labels\n",
      "----------------------------------------\n",
      "Dataset structure verified successfully!\n",
      "\n",
      " Dataset found!\n",
      "Created data.yaml at: /home/savaj.k/PRCV-Project/data/raw/data.yaml\n",
      "\n",
      "============================================================\n",
      "DATASET SUMMARY (6-Class Candlestick Patterns)\n",
      "============================================================\n",
      "\n",
      "Images:\n",
      "  Training:   4,102\n",
      "  Validation: 1,175\n",
      "  Test:       596\n",
      "  Total:      5,873\n",
      "\n",
      "Annotated Instances: 5,873\n",
      "\n",
      "Class Distribution (Training Set):\n",
      "---------------------------------------------\n",
      "  Spinning Top          2211 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Marubozu               648 ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  Gravestone Doji        470 ‚ñà‚ñà‚ñà‚ñà\n",
      "  Dragonfly Doji         303 ‚ñà‚ñà\n",
      "  Hammer                 281 ‚ñà‚ñà\n",
      "  Hanging Man            189 ‚ñà\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Verify Dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: DATA VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if verify_dataset_structure():\n",
    "    print(\"\\n Dataset found!\")\n",
    "    create_data_yaml()\n",
    "    print_dataset_summary()\n",
    "else:\n",
    "    print(\"\\n Dataset not found! Please extract to data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0451b01d-f1f9-4fed-a788-5332d8ed65c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: MODEL TRAINING\n",
      "============================================================\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 108.3MB/s 0.2s0.1s<0.1s\n",
      "‚úÖ Loaded YOLOv8-Small\n",
      "\n",
      "üöÄ Training with 4 GPU(s)\n",
      "\n",
      "Configuration:\n",
      "  - Epochs: 50\n",
      "  - Batch Size: 64\n",
      "  - Image Size: 640\n",
      "------------------------------------------------------------\n",
      "New https://pypi.org/project/ultralytics/8.3.235 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.234 üöÄ Python-3.10.16 torch-2.5.1 CUDA:0 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "                                                 CUDA:1 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "                                                 CUDA:2 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "                                                 CUDA:3 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/savaj.k/PRCV-Project/data/raw/data.yaml, degrees=0.0, deterministic=True, device=0,1,2,3, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=candlestick_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/savaj.k/PRCV-Project/models/candlestick_v1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.head.Detect           [6, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,137,922 parameters, 11,137,906 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/miniconda/envs/eai/bin/python -m torch.distributed.run --nproc_per_node 4 --master_port 39159 /home/savaj.k/.config/Ultralytics/DDP/_temp_j2jjmx4423307523109120.py\n",
      "Ultralytics 8.3.234 üöÄ Python-3.10.16 torch-2.5.1 CUDA:0 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "                                                 CUDA:1 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "                                                 CUDA:2 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "                                                 CUDA:3 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 26.5MB/s 0.2s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 7.6¬±7.0 MB/s, size: 11.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/savaj.k/PRCV-Project/data/raw/train/labels... 4102 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4102/4102 1.8Kit/s 2.2s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/savaj.k/PRCV-Project/data/raw/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 23.7¬±8.6 MB/s, size: 11.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/savaj.k/PRCV-Project/data/raw/valid/labels... 1175 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1175/1175 981.0it/s 1.2s.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/savaj.k/PRCV-Project/data/raw/valid/labels.cache\n",
      "Plotting labels to /home/savaj.k/PRCV-Project/models/candlestick_v1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 28 dataloader workers\n",
      "Logging results to \u001b[1m/home/savaj.k/PRCV-Project/models/candlestick_v1\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      4.37G      1.081      4.422      1.257          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.3it/s 28.2s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 1.3s/it 12.9s.4s\n",
      "                   all       1175       1175          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      4.37G     0.7618      1.971      1.101          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.6it/s 24.6s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.3it/s 4.4s.5ss\n",
      "                   all       1175       1175   0.000584      0.169   0.000655   0.000169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      4.37G     0.7074      1.799      1.057          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 30.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.3it/s 4.4s.5ss\n",
      "                   all       1175       1175      0.334     0.0301   0.000443   0.000146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      4.37G     0.6235      1.776      1.019          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 30.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.124      0.317      0.114     0.0899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      4.37G      0.547      1.679     0.9806          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 30.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.204      0.516      0.206       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      4.37G     0.5284      1.647     0.9782          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 30.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.3it/s 4.4s.5ss\n",
      "                   all       1175       1175      0.283      0.365      0.245      0.221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      4.37G     0.5039      1.568     0.9629          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 30.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.139      0.406      0.128      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      4.37G     0.4727      1.562     0.9529          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 31.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.245      0.488      0.261      0.245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      4.37G     0.4703      1.569     0.9611          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 31.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.834     0.0519    0.00123   0.000588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      4.37G     0.4512      1.555     0.9512          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 31.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.183       0.33      0.155      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      4.37G      0.436      1.548     0.9408          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 30.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175       0.32      0.542      0.299       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      4.37G       0.43      1.544      0.934          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.1it/s 31.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.2it/s 4.5s.5ss\n",
      "                   all       1175       1175      0.267       0.56      0.311      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      4.37G     0.4063      1.501     0.9273          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.6it/s 24.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.5s.3s\n",
      "                   all       1175       1175      0.736      0.146      0.087     0.0567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      4.37G     0.4067      1.528     0.9361          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.3it/s 28.2s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.315      0.493      0.338      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      4.37G     0.3809      1.464      0.909          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.249      0.562      0.284      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      4.37G     0.3795      1.456     0.9205          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.835     0.0437   0.000821   0.000204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      4.37G     0.3803      1.493     0.9274          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.259      0.559      0.301      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      4.37G     0.3581      1.417     0.9144          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.5s.3s\n",
      "                   all       1175       1175      0.187      0.418       0.23      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      4.37G     0.3528      1.439     0.9136          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.287      0.602      0.347      0.342\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      4.37G     0.3668      1.416     0.9289          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.232      0.492      0.309      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      4.37G     0.3554      1.405     0.9106          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.5s.3s\n",
      "                   all       1175       1175      0.168      0.314     0.0967     0.0844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      4.37G     0.3429      1.413     0.9104          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.2s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.5s.3s\n",
      "                   all       1175       1175      0.288      0.608      0.359      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      4.37G     0.3402      1.413     0.9044          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175       0.28      0.622      0.332      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      4.37G     0.3334      1.413     0.8947          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.291      0.616       0.36      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      4.37G     0.3044      1.371      0.885          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.227      0.571      0.251      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      4.37G     0.3215      1.329     0.8971          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.358      0.622      0.434      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      4.37G     0.3152      1.248     0.8898          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175    0.00822      0.118    0.00547    0.00174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      4.37G     0.3176      1.249      0.898          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.206       0.35      0.198      0.172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      4.37G     0.3171      1.237     0.9012          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.362      0.721      0.486       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      4.37G     0.3092      1.228     0.8898          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.363      0.712      0.496       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      4.37G     0.3006      1.181     0.8848          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.394       0.61      0.478      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      4.37G     0.2925      1.129     0.8859          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.377      0.764      0.504      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      4.37G     0.2843      1.141     0.8783          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.3s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175       0.14      0.143     0.0545     0.0508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      4.37G     0.2789      1.138     0.8817          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.3s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.409      0.692      0.518      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      4.37G      0.283      1.125     0.8838          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.422      0.728      0.535      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      4.37G     0.2766      1.138     0.8885          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175       0.42      0.723      0.554       0.55\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      4.37G     0.2672      1.142     0.8753          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.423      0.702      0.532      0.529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      4.37G     0.2702      1.172     0.8699          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.417      0.759      0.569      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      4.37G     0.2733      1.054     0.8917          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.417      0.748       0.55      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      4.37G     0.2436      1.096     0.8764          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.402      0.734      0.547      0.545\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      4.37G     0.1584     0.8266     0.7926          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.6it/s 25.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.407      0.684      0.522      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      4.37G      0.155     0.7976     0.7924          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175       0.43      0.702      0.545      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      4.37G     0.1508     0.7954     0.7944          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.2s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.417      0.761      0.575      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      4.37G     0.1407     0.7618     0.7899          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.436      0.737       0.58      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      4.37G     0.1358     0.7756     0.7804          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.4s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.435      0.753      0.574      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      4.37G     0.1386     0.7412      0.788          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.418      0.782      0.581       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      4.37G     0.1308     0.7498     0.7834          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.447      0.766      0.591      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      4.37G     0.1256      0.749     0.7851          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.456      0.751      0.601        0.6\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      4.37G     0.1207      0.693     0.7859          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.469      0.742      0.604      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      4.37G     0.1148     0.7009     0.7806          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 65/65 2.7it/s 24.1s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 4.1it/s 2.4s.3s\n",
      "                   all       1175       1175      0.467      0.732      0.607      0.606\n",
      "\n",
      "50 epochs completed in 0.416 hours.\n",
      "Optimizer stripped from /home/savaj.k/PRCV-Project/models/candlestick_v1/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /home/savaj.k/PRCV-Project/models/candlestick_v1/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /home/savaj.k/PRCV-Project/models/candlestick_v1/weights/best.pt...\n",
      "Model summary (fused): 72 layers, 11,127,906 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.8it/s 2.7s.3s\n",
      "                   all       1175       1175      0.468      0.739      0.608      0.606\n",
      "        Dragonfly Doji         95         95      0.407      0.768      0.482      0.479\n",
      "       Gravestone Doji        144        144      0.503      0.764      0.673      0.672\n",
      "                Hammer         83         83      0.402      0.639      0.545      0.544\n",
      "           Hanging Man         52         52      0.236      0.365      0.211       0.21\n",
      "              Marubozu        183        183      0.616      0.929      0.868      0.866\n",
      "          Spinning Top        618        618      0.646      0.968      0.867      0.867\n",
      "Speed: 0.0ms preprocess, 1.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/savaj.k/PRCV-Project/models/candlestick_v1\u001b[0m\n",
      "\n",
      "‚úÖ Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Training\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load YOLOv8 Small model\n",
    "model = YOLO('yolov8s.pt')\n",
    "print(\"Loaded YOLOv8-Small\")\n",
    "\n",
    "# Check GPU count\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"\\n Training with {num_gpus} GPU(s)\")\n",
    "\n",
    "# Training configuration\n",
    "train_config = {\n",
    "    'data': str(DATASET_YAML),\n",
    "    'epochs': 50,\n",
    "    'patience': 15,\n",
    "    'batch': 16 * max(1, num_gpus),\n",
    "    'imgsz': 640,\n",
    "    'device': list(range(num_gpus)) if num_gpus > 1 else 0,\n",
    "    'workers': 8,\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.01,\n",
    "    'lrf': 0.01,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'box': 7.5,\n",
    "    'cls': 0.5,\n",
    "    'dfl': 1.5,\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'project': 'models',\n",
    "    'name': 'candlestick_v1',\n",
    "    'exist_ok': True,\n",
    "    'verbose': True,\n",
    "    'plots': True\n",
    "}\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  - Epochs: {train_config['epochs']}\")\n",
    "print(f\"  - Batch Size: {train_config['batch']}\")\n",
    "print(f\"  - Image Size: {train_config['imgsz']}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Start training\n",
    "results = model.train(**train_config)\n",
    "print(\"\\n Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dafd4152-ee51-414e-9250-a83bfe2e997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3: SAVE WEIGHTS & EVALUATE\n",
      "============================================================\n",
      " Weights saved to: /home/savaj.k/PRCV-Project/models/weights/best.pt\n",
      "   Size: 22.5 MB\n",
      "\n",
      " Running Validation...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.10.16 torch-2.5.1 CUDA:0 (Tesla P100-PCIE-12GB, 12194MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 48.1¬±13.8 MB/s, size: 12.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/savaj.k/PRCV-Project/data/raw/valid/labels.cache... 1175 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1175/1175 1.9Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 6.6it/s 11.3s0.1s\n",
      "                   all       1175       1175      0.468      0.735      0.607      0.606\n",
      "        Dragonfly Doji         95         95      0.408      0.768       0.48      0.477\n",
      "       Gravestone Doji        144        144      0.504      0.764      0.672      0.671\n",
      "                Hammer         83         83      0.404      0.639      0.546      0.546\n",
      "           Hanging Man         52         52       0.23      0.345      0.211       0.21\n",
      "              Marubozu        183        183      0.616      0.929      0.868      0.866\n",
      "          Spinning Top        618        618      0.646      0.968      0.867      0.867\n",
      "Speed: 0.5ms preprocess, 5.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/savaj.k/PRCV-Project/runs/detect/val2\u001b[0m\n",
      "\n",
      "============================================================\n",
      "VALIDATION RESULTS\n",
      "============================================================\n",
      "  mAP@50:    0.6074\n",
      "  mAP@50-95: 0.6062\n",
      "  Precision: 0.4681\n",
      "  Recall:    0.7354\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Save Weights & Evaluate\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: SAVE WEIGHTS & EVALUATE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Copy best weights to production path\n",
    "run_weights = Path('models/candlestick_v1/weights/best.pt')\n",
    "final_weights = WEIGHTS_DIR / 'best.pt'\n",
    "\n",
    "if run_weights.exists():\n",
    "    shutil.copy(run_weights, final_weights)\n",
    "    print(f\" Weights saved to: {final_weights}\")\n",
    "    print(f\"   Size: {final_weights.stat().st_size / 1e6:.1f} MB\")\n",
    "else:\n",
    "    print(\" Weights not found. Check training logs.\")\n",
    "\n",
    "# Run validation\n",
    "print(\"\\n Running Validation...\")\n",
    "val_results = model.val(data=str(DATASET_YAML), split='val')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  mAP@50:    {val_results.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"  Precision: {val_results.box.mp:.4f}\")\n",
    "print(f\"  Recall:    {val_results.box.mr:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797a4a56-4272-4657-a550-4fc706d758f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: TEST DETECTION\n",
      "============================================================\n",
      "Model loaded: best.pt\n",
      "Found 1175 validation images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DETECTED PATTERNS: 1\n",
      "==================================================\n",
      "\n",
      "  1. Spinning Top\n",
      "     Confidence: 81.0%\n",
      "     Signal: ‚ö™ NEUTRAL\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test Detection\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4: TEST DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from src.config import BULLISH_PATTERNS, BEARISH_PATTERNS\n",
    "\n",
    "# Load detector\n",
    "detector = PatternDetector(model_path=WEIGHTS_DIR / 'best.pt')\n",
    "\n",
    "# Get validation images\n",
    "valid_images = list((RAW_DATA_DIR / \"valid\" / \"images\").glob(\"*.jpg\"))\n",
    "if not valid_images:\n",
    "    valid_images = list((RAW_DATA_DIR / \"valid\" / \"images\").glob(\"*.png\"))\n",
    "\n",
    "print(f\"Found {len(valid_images)} validation images\")\n",
    "\n",
    "# Test on sample image\n",
    "if valid_images:\n",
    "    sample_img = valid_images[0]\n",
    "    detections, annotated = detector.detect(str(sample_img), confidence_threshold=0.20)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(annotated)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Detected: {len(detections)} patterns\")\n",
    "    plt.show()\n",
    "    \n",
    "    detector.print_detections(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a080b669-6259-4c03-8712-e9529834198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 5: DEMO VISUALIZATION (All Pattern Types)\n",
      "============================================================\n",
      "Searching for examples of each pattern...\n",
      "\n",
      "Found patterns:\n",
      "  - Spinning Top: 2 examples\n",
      "  - Gravestone Doji: 2 examples\n",
      "  - Dragonfly Doji: 2 examples\n",
      "  - Hammer: 2 examples\n",
      "  - Marubozu: 2 examples\n",
      "  - Hanging Man: 2 examples\n",
      "\n",
      "Showing 6 different patterns in demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_334776/3960105240.py:67: UserWarning: Glyph 128994 (\\N{LARGE GREEN CIRCLE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_334776/3960105240.py:67: UserWarning: Glyph 128308 (\\N{LARGE RED CIRCLE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_334776/3960105240.py:68: UserWarning: Glyph 128994 (\\N{LARGE GREEN CIRCLE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(\"final_demo.png\", dpi=150, bbox_inches='tight')\n",
      "/tmp/ipykernel_334776/3960105240.py:68: UserWarning: Glyph 128308 (\\N{LARGE RED CIRCLE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(\"final_demo.png\", dpi=150, bbox_inches='tight')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demo saved as 'final_demo.png'\n",
      "\n",
      "============================================================\n",
      "DETECTION SUMMARY BY CLASS\n",
      "============================================================\n",
      "  üü¢ Dragonfly Doji: 2 detections found\n",
      "  üî¥ Gravestone Doji: 2 detections found\n",
      "  üü¢ Hammer: 2 detections found\n",
      "  üî¥ Hanging Man: 2 detections found\n",
      "  ‚ö™ Marubozu: 2 detections found\n",
      "  ‚ö™ Spinning Top: 2 detections found\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create Demo Visualization - FIND ALL PATTERN TYPES\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 5: DEMO VISUALIZATION (All Pattern Types)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from src.config import BULLISH_PATTERNS, BEARISH_PATTERNS, CLASS_NAMES\n",
    "from collections import defaultdict\n",
    "\n",
    "# Find one example of each pattern type\n",
    "pattern_examples = defaultdict(list)\n",
    "\n",
    "print(\"Searching for examples of each pattern...\")\n",
    "for img_path in valid_images:\n",
    "    dets, annotated = detector.detect(str(img_path), confidence_threshold=0.25)\n",
    "    \n",
    "    if dets:\n",
    "        pattern = dets[0].pattern\n",
    "        if len(pattern_examples[pattern]) < 2:  # Keep up to 2 examples per pattern\n",
    "            pattern_examples[pattern].append((img_path, dets, annotated))\n",
    "\n",
    "print(f\"\\nFound patterns:\")\n",
    "for pattern, examples in pattern_examples.items():\n",
    "    print(f\"  - {pattern}: {len(examples)} examples\")\n",
    "\n",
    "# Create visualization with one of each pattern\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Get one example per pattern (prioritize variety)\n",
    "demo_images = []\n",
    "for pattern in CLASS_NAMES:\n",
    "    if pattern in pattern_examples and pattern_examples[pattern]:\n",
    "        demo_images.append(pattern_examples[pattern][0])\n",
    "\n",
    "# Fill remaining slots with any pattern\n",
    "for pattern, examples in pattern_examples.items():\n",
    "    if len(demo_images) >= 6:\n",
    "        break\n",
    "    for ex in examples:\n",
    "        if ex not in demo_images and len(demo_images) < 6:\n",
    "            demo_images.append(ex)\n",
    "\n",
    "print(f\"\\nShowing {len(demo_images)} different patterns in demo\")\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx < len(demo_images):\n",
    "        img_path, dets, annotated = demo_images[idx]\n",
    "        \n",
    "        ax.imshow(annotated)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        pattern = dets[0].pattern\n",
    "        conf = dets[0].confidence\n",
    "        \n",
    "        if pattern in BULLISH_PATTERNS:\n",
    "            color, signal = 'green', 'üü¢ BULLISH'\n",
    "        elif pattern in BEARISH_PATTERNS:\n",
    "            color, signal = 'red', 'üî¥ BEARISH'\n",
    "        else:\n",
    "            color, signal = 'gray', '‚ö™ NEUTRAL'\n",
    "        \n",
    "        ax.set_title(f\"{pattern}\\n{signal} | {conf:.0%}\", fontsize=12, color=color, fontweight='bold')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"YOLOv8 Candlestick Pattern Detection - All 6 Classes\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_demo.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDemo saved as 'final_demo.png'\")\n",
    "\n",
    "# Also show per-class summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETECTION SUMMARY BY CLASS\")\n",
    "print(\"=\" * 60)\n",
    "for pattern in CLASS_NAMES:\n",
    "    count = len(pattern_examples.get(pattern, []))\n",
    "    emoji = \"üü¢\" if pattern in BULLISH_PATTERNS else \"üî¥\" if pattern in BEARISH_PATTERNS else \"‚ö™\"\n",
    "    print(f\"  {emoji} {pattern}: {count} detections found\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3612e6e6-0a40-4cb7-b648-435140ae78dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " PROJECT COMPLETE!\n",
      "============================================================\n",
      "\n",
      " Files created:\n",
      "   - Model weights: /home/savaj.k/PRCV-Project/models/weights/best.pt\n",
      "   - Demo image: final_demo.png\n",
      "\n",
      " To run Flask webapp:\n",
      "   cd webapp && python app.py\n",
      "\n",
      " Classes trained: Dragonfly Doji, Gravestone Doji, Hammer, Hanging Man, Marubozu, Spinning Top\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" PROJECT COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n Files created:\")\n",
    "print(f\"   - Model weights: {WEIGHTS_DIR / 'best.pt'}\")\n",
    "print(f\"   - Demo image: final_demo.png\")\n",
    "print(f\"\\n To run Flask webapp:\")\n",
    "print(f\"   cd webapp && python app.py\")\n",
    "print(f\"\\n Classes trained: {', '.join(CLASS_NAMES)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd306c-4be7-4630-822c-cecd6612790e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
